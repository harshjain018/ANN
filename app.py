# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16S4qVBcycrwvCu59P9ycqrQJGkreK_Z0
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import plotly.express as px
from io import StringIO
import requests

# Page Configuration
st.set_page_config(
    page_title="Customer Spending Analysis",
    page_icon="ðŸ’³",
    layout="wide"
)

# Load Data Function
@st.cache_data
def load_data():
    # Sample data loading - replace with your actual data source
    data_url = "https://raw.githubusercontent.com/yourusername/yourrepo/main/credit_card_data.csv"
    try:
        response = requests.get(data_url)
        response.raise_for_status()
        df = pd.read_csv(StringIO(response.text))

        # Data preprocessing
        df['Converted'] = (df['PURCHASES'] > df['PURCHASES'].median()).astype(int)
        df['CREDIT_LIMIT'].fillna(df['CREDIT_LIMIT'].median(), inplace=True)
        df['MINIMUM_PAYMENTS'].fillna(df['MINIMUM_PAYMENTS'].median(), inplace=True)
        if 'CUST_ID' in df.columns:
            df.drop(columns=['CUST_ID'], inplace=True)

        return df
    except Exception as e:
        st.error(f"Error loading data: {str(e)}")
        return pd.DataFrame()

# Initialize session state
if 'model' not in st.session_state:
    st.session_state.model = None
if 'history' not in st.session_state:
    st.session_state.history = None

# Main App
def main():
    st.title("ðŸ’³ ANN Customer Spending Analysis Dashboard")
    st.markdown("""
    This dashboard analyzes credit card customer data to classify customers as **High Spenders** or **Low Spenders**
    using an Artificial Neural Network.
    """)

    # Sidebar Configuration
    st.sidebar.header("Model Configuration")
    epochs = st.sidebar.slider("Number of Epochs", 5, 50, 10)
    batch_size = st.sidebar.selectbox("Batch Size", [32, 64, 128, 256], index=2)
    hidden_units = st.sidebar.slider("Hidden Units in First Layer", 32, 256, 128, step=32)
    dropout_rate = st.sidebar.slider("Dropout Rate", 0.1, 0.5, 0.3, step=0.1)

    # Load Data
    df = load_data()

    if df.empty:
        st.warning("Data loading failed. Please check your data source.")
        return

    # Data Exploration Section
    st.header("ðŸ“Š Data Exploration")

    if st.checkbox("Show Raw Data"):
        st.subheader("Raw Data Preview")
        st.dataframe(df.head())

    st.subheader("Data Statistics")
    st.dataframe(df.describe())

    # Visualizations
    st.subheader("Data Visualizations")
    tab1, tab2, tab3 = st.tabs(["Distributions", "Correlations", "Spending Patterns"])

    with tab1:
        fig, ax = plt.subplots(1, 2, figsize=(12, 5))
        sns.histplot(df['BALANCE'], bins=30, kde=True, ax=ax[0])
        ax[0].set_title('Balance Distribution')
        sns.histplot(df['PURCHASES'], bins=30, kde=True, ax=ax[1])
        ax[1].set_title('Purchases Distribution')
        st.pyplot(fig)

    with tab2:
        numerical_cols = ['BALANCE', 'PURCHASES', 'CREDIT_LIMIT', 'PAYMENTS']
        plt.figure(figsize=(10, 8))
        sns.heatmap(df[numerical_cols].corr(), annot=True, cmap='coolwarm')
        st.pyplot(plt)

    with tab3:
        df['PAYMENT_RATIO'] = df['PAYMENTS'] / (df['BALANCE'] + 0.0001)
        fig = px.scatter(df, x='BALANCE', y='PAYMENT_RATIO',
                        color='PRC_FULL_PAYMENT',
                        title='Payment Behavior Analysis')
        st.plotly_chart(fig)

    # Model Training Section
    st.header("ðŸ¤– Model Training")

    # Prepare data
    X = df.drop(columns=['Converted'])
    y = df['Converted']
    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

    # Standardize features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)

    if st.button("Train Model"):
        with st.spinner('Training model...'):
            # Build model
            model = Sequential([
                Dense(hidden_units, activation='relu', input_shape=(X_train_scaled.shape[1],)),
                Dropout(dropout_rate),
                Dense(hidden_units//2, activation='relu'),
                Dropout(dropout_rate),
                Dense(1, activation='sigmoid')
            ])

            model.compile(optimizer='adam',
                        loss='binary_crossentropy',
                        metrics=['accuracy'])

            early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

            history = model.fit(
                X_train_scaled, y_train,
                epochs=epochs,
                batch_size=batch_size,
                validation_data=(X_val_scaled, y_val),
                callbacks=[early_stopping],
                verbose=0
            )

            # Store in session state
            st.session_state.model = model
            st.session_state.history = history

            st.success("Model trained successfully!")

    # Model Evaluation
    if st.session_state.model is not None:
        st.subheader("Model Performance")

        # Plot training history
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        ax1.plot(st.session_state.history.history['accuracy'], label='Train Accuracy')
        ax1.plot(st.session_state.history.history['val_accuracy'], label='Validation Accuracy')
        ax1.set_title('Model Accuracy')
        ax1.legend()

        ax2.plot(st.session_state.history.history['loss'], label='Train Loss')
        ax2.plot(st.session_state.history.history['val_loss'], label='Validation Loss')
        ax2.set_title('Model Loss')
        ax2.legend()

        st.pyplot(fig)

        # Evaluation metrics
        y_pred = (st.session_state.model.predict(X_test_scaled) > 0.5).astype(int)
        st.text(classification_report(y_test, y_pred))

        # Confusion matrix
        cm = confusion_matrix(y_test, y_pred)
        fig = px.imshow(cm,
                       labels=dict(x="Predicted", y="Actual", color="Count"),
                       x=['Low Spender', 'High Spender'],
                       y=['Low Spender', 'High Spender'],
                       text_auto=True)
        st.plotly_chart(fig)

    # Prediction Interface
    st.header("ðŸ”® Make Predictions")

    with st.form("prediction_form"):
        st.subheader("Enter Customer Details")

        col1, col2 = st.columns(2)
        with col1:
            balance = st.number_input("Balance", min_value=0.0, value=1000.0)
            purchases = st.number_input("Purchases", min_value=0.0, value=500.0)
            credit_limit = st.number_input("Credit Limit", min_value=0.0, value=3000.0)

        with col2:
            payments = st.number_input("Payments", min_value=0.0, value=800.0)
            minimum_payments = st.number_input("Minimum Payments", min_value=0.0, value=100.0)
            tenure = st.number_input("Tenure (months)", min_value=0, value=12)

        submitted = st.form_submit_button("Predict Spending Category")

        if submitted and st.session_state.model is not None:
            input_data = pd.DataFrame({
                'BALANCE': [balance],
                'PURCHASES': [purchases],
                'CREDIT_LIMIT': [credit_limit],
                'PAYMENTS': [payments],
                'MINIMUM_PAYMENTS': [minimum_payments],
                'TENURE': [tenure],
                'BALANCE_FREQUENCY': [df['BALANCE_FREQUENCY'].median()],
                'PURCHASES_FREQUENCY': [df['PURCHASES_FREQUENCY'].median()],
                'ONEOFF_PURCHASES_FREQUENCY': [df['ONEOFF_PURCHASES_FREQUENCY'].median()],
                'PURCHASES_INSTALLMENTS_FREQUENCY': [df['PURCHASES_INSTALLMENTS_FREQUENCY'].median()],
                'CASH_ADVANCE_FREQUENCY': [df['CASH_ADVANCE_FREQUENCY'].median()],
                'CASH_ADVANCE_TRX': [df['CASH_ADVANCE_TRX'].median()],
                'PRC_FULL_PAYMENT': [df['PRC_FULL_PAYMENT'].median()]
            })

            input_scaled = scaler.transform(input_data)
            prediction = st.session_state.model.predict(input_scaled)[0][0]
            prediction_class = "High Spender" if prediction > 0.5 else "Low Spender"
            confidence = prediction if prediction_class == "High Spender" else 1 - prediction

            st.subheader("Prediction Result")
            st.success(f"Predicted Category: **{prediction_class}**")
            st.info(f"Confidence: {confidence:.2%}")

            # Probability visualization
            fig = px.bar(x=['Low Spender', 'High Spender'],
                         y=[1 - prediction, prediction],
                         color=['Low Spender', 'High Spender'],
                         labels={'x': 'Category', 'y': 'Probability'},
                         title='Prediction Probabilities')
            st.plotly_chart(fig)

if __name__ == "__main__":
    main()

